{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from datetime import datetime\n",
    "import re\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dieses Modell enthält Regeln und Algorithmen, um Text auf Englisch zu verarbeiten\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Liste der Schlüsselwörter für Berufserfahrung\n",
    "experience_keywords = [\n",
    "    \"experience\", \"Experience\", \"work history\", \"employment\", \"career\", \"professional experience\",\n",
    "    \"work experience\", \"employment history\", \"career history\", \"Professional Experience\", \"WORKING EXPERIENCE\"]\n",
    "experience_keywords_regex = r\"(?m)^\\s*(\" + \"|\".join(map(re.escape, experience_keywords)) + r\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of common words associated with company names\n",
    "company_keywords = [\n",
    "    \"Employed\",\"Bank\", \"Boutique\",\"Designer\",\"Secretary\",\"Security\",\n",
    "    \"Inc.\",\"inc\", \"Incorporated\", \"Ltd.\",\"ltd\", \"Limited\", \"LLC\", \"LLP\", \"PLC\",\n",
    "    \"Corp\", \"Corporation\", \"Group\", \"Agency\", \"Consultancy\", \"Partners\",\n",
    "    \"Holdings\", \"Associates\", \"Independent\", \"Innovative\", \"GmbH\",\"american express\"\n",
    "    \"ENTERPRISES\",\"Institut\",\"Institutes\",\"Institute\",\"Mediatech\"\n",
    "]\n",
    "company_keywords_regex = r\"(?:\\w+\\s+){0,3}\\b(\" + \"|\".join(map(re.escape, company_keywords)) + r\")\\b(?:\\s+\\w+){0,3}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of common job position keywords\n",
    "job_position_keywords = [\n",
    "    \"Developer\", \"Engineer\", \"Manager\", \"Consultant\", \"Technician\",\"Fixed\"\n",
    "    \"Analyst\", \"Specialist\", \"Supervisor\", \"Coordinator\", \"HR\", \"Recruiter\",\n",
    "    \"Director\", \"Driver\", \"Sales\", \"Customer Support\", \"Account Executive\",\n",
    "    \"Data Scientist\", \"Software\", \"Product Manager\", \"Project Manager\",\n",
    "    \"Freelance\", \"Software\", \"Administrator\", \"Technician\", \"Team Leader\",\n",
    "    \"Designer\",\"Secretary\",\"Security\",\"associate\",\"Designers\",\"business\",\n",
    "    \"analyst\",\"Junior\",\"Senior\",\"Mecanical\"\n",
    "]\n",
    "job_position_keywords_regex = r\"(?:\\w+\\s+){0,3}\\b(\" + \"|\".join(map(re.escape, job_position_keywords)) + r\")\\b(?:\\s+\\w+){0,3}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = r\"[-:/\\._;!?@#\\$%\\^&\\*\\(\\)\\[\\]{}<>'\\\"\\\\\\/|`~+=]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#EXTRACT EXPERIENCE SECTION\n",
    "def extract_experience_section(pdf_file):\n",
    "    end_keywords = r\"^(personal|Academic|Hobbies|education|skills|certifications|achievements|summary|references|DEGREE)\"\n",
    "    experience_section = \"\"\n",
    "    inside_experience_section = False\n",
    "    try:\n",
    "        # Iterate over pages\n",
    "        for page_layout in extract_pages(pdf_file):\n",
    "            for element in page_layout:\n",
    "                if isinstance(element, LTTextContainer):\n",
    "                    section_text = \"\"\n",
    "                    for text_line in element:\n",
    "                        line_text = text_line.get_text().strip()\n",
    "                        if not line_text:\n",
    "                            continue  # Skip empty lines\n",
    "                        # If we're inside the experience section, add text to the section\n",
    "                        if inside_experience_section:\n",
    "                            # Stop if we encounter an end keyword\n",
    "                            if re.search(end_keywords, line_text, re.I):\n",
    "                                return experience_section.strip()  # End of the section\n",
    "                            section_text += line_text + \"\\n\"\n",
    "                        # Check if the current line is the start of the experience section\n",
    "                        if not inside_experience_section and re.search(experience_keywords_regex, line_text, re.I):\n",
    "                            inside_experience_section = True\n",
    "                            section_text += line_text + \"\\n\"\n",
    "                    if section_text:\n",
    "                        experience_section += section_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error while extracting experience section: {e}\")\n",
    "    return experience_section.strip() if experience_section else \"No experience section found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#EXTRACT EXPERIENCE DATES\n",
    "date_pattern = re.compile(r\"\"\"\n",
    "    (?P<start_date>                                      # Named capture group for the start date\n",
    "        ([A-Za-z]+[-\\s]?\\d{4}|                           # Matches month name followed by a year, e.g., \"April 2010\" or \"April-2010\"\n",
    "        \\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\n",
    "        \\d{2,4}|                  # Matches dates in DD/MM/YYYY, MM/DD/YYYY, etc., e.g., \"12/11/1992\" or \"11-12-1992\"\n",
    "        \\d{4}[/-]\\d{1,2}[/-]\\d{1,2})                    # Matches dates in YYYY/MM/DD, e.g., \"1992/11/12\" or \"1992-11-12\"\n",
    "    )\n",
    "    \\s?([tT]o|–|-|–|—)\\s?                                  # Matches various separators like 'to', '-', '–' used between the start and end dates\n",
    "    (?P<end_date>                                        # Named capture group for the end date\n",
    "        ([A-Za-z]+[-\\s]?\\d{4}|                           # Matches end date month-year, e.g., \"April-2011\" or \"April 2011\"\n",
    "        \\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|                   # Matches end date in DD/MM/YYYY or MM/DD/YYYY\n",
    "        \\d{4}[/-]\\d{1,2}[/-]\\d{1,2}|                     # Matches end date in YYYY/MM/DD\n",
    "        ([pP]resent|[tT]oDate|[tT]ill now))           # Matches keywords like \"Present\", \"ToDate\", \"Till now\"\n",
    "    )\n",
    "\"\"\", re.VERBOSE)\n",
    "# extract date from experience section\n",
    "def extract_experience_date(text):\n",
    "    lines = text.split('\\n')\n",
    "    list_dates = []\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Remove extra spaces around the line\n",
    "        if re.search(date_pattern, line):  # If the line contains a date\n",
    "            list_dates.append(re.search(date_pattern, line).group())  # Assign id=\"date\"\n",
    "    return list_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_full_month_name(month_str_year):\n",
    "    # Dictionary mapping the first three letters to full month names\n",
    "    month_mapping = {\n",
    "        'Jan': 'January', 'Feb': 'February', 'Mar': 'March', 'Apr': 'April',\n",
    "        'May': 'May', 'Jun': 'June', 'Jul': 'July', 'Aug': 'August',\n",
    "        'Sep': 'September', 'Oct': 'October', 'Nov': 'November', 'Dec': 'December'\n",
    "    }\n",
    "    parts = month_str_year.split()\n",
    "    if len(parts) != 2:\n",
    "        return month_str_year  # Return as is if it doesn't have both a month and year\n",
    "    month_abbr = parts[0][:3].capitalize()  # Extract and capitalize first 3 letters of the month\n",
    "    year = parts[1]  # The year remains the same\n",
    "    full_month = month_mapping.get(month_abbr, None)\n",
    "    if full_month:\n",
    "        return f\"{full_month} {year}\"\n",
    "    else:\n",
    "        return month_str_year  # Return the original string if no match is found\n",
    "\n",
    "def convert_to_full_date(date_str):\n",
    "    try:\n",
    "        date_str=get_full_month_name(date_str)\n",
    "        if date_str in [\"ToDate\", \"Present\", \"Till now\"]:\n",
    "            print(\"IM IN CONVERT FUNCTION\")\n",
    "            return datetime.now().strftime(\"%B %Y\")\n",
    "        match = re.match(r\"([A-Za-z]+)(\\d{4})\", date_str)\n",
    "        if match:\n",
    "            month = match.group(1)  # Extract the month part\n",
    "            year = match.group(2)  # Extract the year part\n",
    "            return f\"{month} {year}\"\n",
    "        if '-' in date_str:\n",
    "            return datetime.strptime(date_str, \"%b-%Y\").strftime(\"%B %Y\")\n",
    "        else:\n",
    "            return datetime.strptime(date_str, \"%b %Y\").strftime(\"%B %Y\")\n",
    "    except ValueError:\n",
    "        return date_str\n",
    "\n",
    "def process_date_range(date_range):\n",
    "    date_range = re.sub(r\"[-–_—]\", \" to \", date_range)\n",
    "    if 'to' in date_range:\n",
    "        parts = date_range.split('to')\n",
    "        start_date = parts[0].strip()\n",
    "        end_date = parts[1].strip()\n",
    "        start_date_full = convert_to_full_date(start_date)\n",
    "        end_date_full = convert_to_full_date(end_date)\n",
    "        if len(start_date_full.split()) == 1:\n",
    "            start_date_full = f\"January {start_date_full}\"\n",
    "        if len(end_date_full.split()) == 1:\n",
    "            end_date_full = f\"January {end_date_full}\"\n",
    "        start = datetime.strptime(start_date_full, '%B %Y')\n",
    "        end = datetime.strptime(end_date_full, '%B %Y')\n",
    "        return f\"[{start.strftime('%m/%Y')} - {end.strftime('%m/%Y')}]\"\n",
    "    return date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_lines(lines):\n",
    "    words_to_remove = [\"company\", \"designation\", \"role\", \"position\", \"title\"]\n",
    "    remove_words_regex = r\"^\\s*(?:\" + \"|\".join(words_to_remove) + r\")\\s+\"\n",
    "    cleaned_lines = [re.sub(r\"[\\uf000-\\uffff]\", \"\", line).strip() for line in lines]\n",
    "    cleaned_line = [re.sub(remove_words_regex, \"\", line, flags=re.IGNORECASE) for line in cleaned_lines]\n",
    "    cleaned_line = [re.sub(r\"\\s{2,}\", \" \", line).strip() for line in cleaned_line ]\n",
    "    formatted_lines = [line.rstrip(':') for line in cleaned_line]\n",
    "    return formatted_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to extract company name from a line\n",
    "def extract_company_name(text):\n",
    "    doc=nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ORG\" :\n",
    "            return ent.text\n",
    "        for keyword in company_keywords:\n",
    "            if ent.label_ == \"ORG\" or keyword in ent.text:\n",
    "                return ent.text\n",
    "    return \"\"  # Return empty string if no company name found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to extract job position from a line\n",
    "def extract_position_name(line_s):\n",
    "    if any(keyword.lower() in line_s.lower() for keyword in job_position_keywords):\n",
    "        return line_s\n",
    "    doc = nlp(line_s)\n",
    "    for token in doc:\n",
    "        if token.text.lower() in ['as', 'hired', 'position', 'served']:\n",
    "            if token.i + 2 <= len(doc):\n",
    "                position = doc[token.i + 1: token.i + 3]\n",
    "                return position.text\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def correct_dates_in_lines(lines):\n",
    "    corrected_lines = []\n",
    "    current_date=datetime.now().strftime(\"%b %Y\")\n",
    "    for line in lines:\n",
    "        line = line.lower()\n",
    "        day_month_year_pattern = r'\\b\\d{1,2}\\s+([A-Za-z]+)\\s+(\\d{4})\\b'\n",
    "        cleaned_text = re.sub(day_month_year_pattern, r'\\1 \\2', line)\n",
    "        corrected_date= re.sub(r\"(\\b[A-Za-z]+)[-–.](\\d{4})\", r\"\\1 \\2\", cleaned_text)\n",
    "        corrected_line = re.sub(r'([a-zA-Z]+)(\\d{4})', r'\\1 \\2', corrected_date)\n",
    "        corrected_line = re.sub(r'(\\d{4})(-)([a-zA-Z])', r'\\1 - \\3', corrected_line)\n",
    "        corrected_line = re.sub(r'(\\d{4})(\\s)(\\b(present|till|todate)\\b)', r'\\1 - \\3', corrected_line)\n",
    "        corrected_line = re.sub(r'\\b(present|till|todate)\\b', current_date, corrected_line, flags=re.IGNORECASE)\n",
    "        corrected_lines.append(corrected_line)\n",
    "    return corrected_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to process each line of the CV\n",
    "def process_experience_section(text):\n",
    "    lines = text.split('\\n')\n",
    "    lines = correct_dates_in_lines(lines)\n",
    "    result = []\n",
    "    processed_dates = set()\n",
    "    processed_company=set()\n",
    "    processed_position=set()\n",
    "    # Iterate over each line and check if it matches the date pattern\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        def matching(line):\n",
    "            company_name = \"\"\n",
    "            position_name = \"\"\n",
    "            match = re.search(date_pattern, line)\n",
    "            if match:\n",
    "                date = match.group()\n",
    "                if date not in processed_dates:\n",
    "                    processed_dates.add(date)\n",
    "                    output = process_date_range(date)\n",
    "                    start = max(0, i - 2)\n",
    "                    end = min(len(lines), i + 3)\n",
    "                    surrounding_lines = lines[start:end]\n",
    "                    surrounding_lines=clean_lines(surrounding_lines)\n",
    "                    index = 0\n",
    "                    while index < len(surrounding_lines):\n",
    "                        print(surrounding_lines[index], index)\n",
    "                        pos_match = re.search(job_position_keywords_regex, surrounding_lines[index], re.IGNORECASE)\n",
    "                        company_match = re.search(company_keywords_regex, surrounding_lines[index], re.IGNORECASE)\n",
    "                        if pos_match and not position_name:\n",
    "                            position = pos_match.group(0).strip()\n",
    "                            if position not in processed_position:\n",
    "                                processed_position.add(position)\n",
    "                                position_name=position\n",
    "\n",
    "                        if company_match and not company_name:\n",
    "                            company = company_match.group(0).strip()\n",
    "                            if company not in processed_company:\n",
    "                                processed_company.add(company)\n",
    "                                company_name=company\n",
    "                        index += 1\n",
    "                    for line_s in surrounding_lines:\n",
    "                        # Extract company name\n",
    "                        if not company_name:\n",
    "                            company_name = extract_company_name(line_s)\n",
    "                        # Extract position name\n",
    "                        if not position_name:\n",
    "                            position_name = extract_position_name(line_s)\n",
    "                    result.append({\n",
    "                        'dates': output,\n",
    "                        'company':company_name if company_name else \"Not found\",\n",
    "                        'position': position_name if position_name else \"Not found\"\n",
    "                    })\n",
    "                return result\n",
    "        if re.search(date_pattern, line) :\n",
    "            matching(line)\n",
    "        doc = nlp(line)\n",
    "        # Use SpaCy's NER to find organization entities (DATE)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"DATE\":\n",
    "                print(doc.text,'TEXT')\n",
    "                correct_dates_in_lines(doc.text)\n",
    "                matching(doc.text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_multiple_pdfs(pdf_dir, output_file):\n",
    "    results = {}\n",
    "    for filename in os.listdir(pdf_dir):\n",
    "        if filename.endswith('.pdf'):\n",
    "            try:\n",
    "                pdf_path = os.path.join(pdf_dir, filename)\n",
    "                # Extract experience section\n",
    "                experience_text = extract_experience_section(pdf_path)\n",
    "                resume = process_experience_section(experience_text)\n",
    "                # Store the result for this PDF\n",
    "                results[filename] = resume\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Fehler beim Verarbeiten der Datei {filename}: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Ein unerwarteter Fehler ist aufgetreten: {e}\")\n",
    "                continue\n",
    "    # Ergebnisse in einer JSON-Datei speichern\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"Ergebnisse wurden in {output_file} gespeichert.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_multiple_pdfs(\"cv_30\", 'label_pred.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
